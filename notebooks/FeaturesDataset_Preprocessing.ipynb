{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "import io\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import folium\n",
        "import selenium\n",
        "import h5py\n",
        "\n",
        "from PIL import Image\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ahUGRFhColMb"
      },
      "outputs": [],
      "source": [
        "all_features = pd.read_pickle(r'../data/all_features.pkl')\n",
        "all_features = all_features.sort_values(by='mesh_id').reset_index(drop=True)\n",
        "all_features = all_features[['mesh_id', 'latitude', 'longitude', 'area', 'prefecture']]\n",
        "all_features = all_features.drop_duplicates(subset=['mesh_id'], keep='first')\n",
        "\n",
        "# reports_selected = pd.read_csv(r'../data/reports_selected.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# For testing purposes, let's use a smaller dataset\n",
        "all_features = all_features[all_features['prefecture'].isin(['tokyo'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mesh_id</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>area</th>\n",
              "      <th>prefecture</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2888</th>\n",
              "      <td>53392307</td>\n",
              "      <td>35.50000</td>\n",
              "      <td>139.4625</td>\n",
              "      <td>1047954</td>\n",
              "      <td>tokyo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2889</th>\n",
              "      <td>53392308</td>\n",
              "      <td>35.50000</td>\n",
              "      <td>139.4750</td>\n",
              "      <td>1047946</td>\n",
              "      <td>tokyo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2898</th>\n",
              "      <td>53392317</td>\n",
              "      <td>35.50833</td>\n",
              "      <td>139.4625</td>\n",
              "      <td>1047847</td>\n",
              "      <td>tokyo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2907</th>\n",
              "      <td>53392326</td>\n",
              "      <td>35.51667</td>\n",
              "      <td>139.4500</td>\n",
              "      <td>1047748</td>\n",
              "      <td>tokyo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2908</th>\n",
              "      <td>53392327</td>\n",
              "      <td>35.51667</td>\n",
              "      <td>139.4625</td>\n",
              "      <td>1047740</td>\n",
              "      <td>tokyo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5079</th>\n",
              "      <td>53396107</td>\n",
              "      <td>35.83333</td>\n",
              "      <td>139.2125</td>\n",
              "      <td>1043833</td>\n",
              "      <td>tokyo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5080</th>\n",
              "      <td>53396108</td>\n",
              "      <td>35.83333</td>\n",
              "      <td>139.2250</td>\n",
              "      <td>1043824</td>\n",
              "      <td>tokyo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5081</th>\n",
              "      <td>53396112</td>\n",
              "      <td>35.84167</td>\n",
              "      <td>139.1500</td>\n",
              "      <td>1043773</td>\n",
              "      <td>tokyo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5128</th>\n",
              "      <td>53396201</td>\n",
              "      <td>35.83333</td>\n",
              "      <td>139.2625</td>\n",
              "      <td>1043796</td>\n",
              "      <td>tokyo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5129</th>\n",
              "      <td>53396202</td>\n",
              "      <td>35.83333</td>\n",
              "      <td>139.2750</td>\n",
              "      <td>1043787</td>\n",
              "      <td>tokyo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1378 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       mesh_id  latitude  longitude     area prefecture\n",
              "2888  53392307  35.50000   139.4625  1047954      tokyo\n",
              "2889  53392308  35.50000   139.4750  1047946      tokyo\n",
              "2898  53392317  35.50833   139.4625  1047847      tokyo\n",
              "2907  53392326  35.51667   139.4500  1047748      tokyo\n",
              "2908  53392327  35.51667   139.4625  1047740      tokyo\n",
              "...        ...       ...        ...      ...        ...\n",
              "5079  53396107  35.83333   139.2125  1043833      tokyo\n",
              "5080  53396108  35.83333   139.2250  1043824      tokyo\n",
              "5081  53396112  35.84167   139.1500  1043773      tokyo\n",
              "5128  53396201  35.83333   139.2625  1043796      tokyo\n",
              "5129  53396202  35.83333   139.2750  1043787      tokyo\n",
              "\n",
              "[1378 rows x 5 columns]"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "lat_width = 75 / 9000\n",
        "lon_height = 0.0125\n",
        "\n",
        "bottom_lat = 35.7015082\n",
        "bottom_lon = 139.5221197"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gradient(img):\n",
        "    kernel = np.ones((5, 5), np.uint8)\n",
        "    imgf = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel)\n",
        "    return imgf\n",
        "\n",
        "def erosion(img):\n",
        "    kernel = np.ones((3, 3), np.uint8)\n",
        "    imgf = cv2.erode(img, kernel, iterations=1)\n",
        "    return imgf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        },
        "id": "gxUz-NZ46XRw",
        "outputId": "592cf4c5-7e2f-492a-95b4-d70975de019b"
      },
      "outputs": [],
      "source": [
        "def preprocessed_image_from_coords(lat, lon, resize=True):\n",
        "    # -------------------\n",
        "    # Creating folium map\n",
        "    # -------------------\n",
        "\n",
        "    north = lat + lat_width\n",
        "    south = lat\n",
        "    east = lon + lon_height\n",
        "    west = lon\n",
        "\n",
        "    def mean(x, y):\n",
        "        return (x + y) / 2\n",
        "\n",
        "    map_obj = folium.Map(location=[\n",
        "        mean(north, south), mean(east, west)], tiles='Cartodb dark_matter no_labels')\n",
        "\n",
        "    square_coordinates = [\n",
        "        (south, west),\n",
        "        (north, west),\n",
        "        (north, east),\n",
        "        (south, east),\n",
        "        (south, west)\n",
        "    ]\n",
        "\n",
        "    folium.PolyLine(\n",
        "        locations=square_coordinates,\n",
        "        weight=7,\n",
        "    ).add_to(map_obj)\n",
        "\n",
        "    map_obj.fit_bounds([(south, west), (north, east)])\n",
        "\n",
        "    # ------------------------\n",
        "    # Save folium map to image\n",
        "    # ------------------------\n",
        "\n",
        "    timeout = 1\n",
        "\n",
        "    img_data = map_obj._to_png(timeout)\n",
        "    img = Image.open(io.BytesIO(img_data))\n",
        "\n",
        "    # ---------------------------\n",
        "    # Detect blue box around mesh\n",
        "    # ---------------------------\n",
        "\n",
        "    image_np = np.array(img)\n",
        "    border_thickness = 8\n",
        "\n",
        "    if image_np.shape[-1] == 4:  # Handle RGBA\n",
        "        image_np = cv2.cvtColor(image_np, cv2.COLOR_RGBA2BGR)\n",
        "    else:\n",
        "        image_np = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    hsv = cv2.cvtColor(image_np, cv2.COLOR_BGR2HSV)\n",
        "    lower_blue = np.array([100, 150, 50])\n",
        "    upper_blue = np.array([140, 255, 255])\n",
        "\n",
        "    mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
        "\n",
        "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    if not contours:\n",
        "        cv2.imshow(image_np)\n",
        "        raise ValueError(f\"No blue box detected in the mesh at {lat}, {lon}\")\n",
        "\n",
        "    largest_contour = max(contours, key=cv2.contourArea)\n",
        "    x, y, w, h = cv2.boundingRect(largest_contour)\n",
        "\n",
        "    x_min = x + border_thickness\n",
        "    y_min = y + border_thickness\n",
        "    x_max = x + w - border_thickness\n",
        "    y_max = y + h - border_thickness\n",
        "\n",
        "    y_min, y_max = min(y_min, y_max), max(y_min, y_max)\n",
        "    x_min, x_max = min(x_min, x_max), max(x_min, x_max)\n",
        "\n",
        "    cropped_np = image_np[y_min:y_max, x_min:x_max]\n",
        "    cv2_image = cv2.cvtColor(cropped_np, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    cv2_image_copy = cv2_image.copy()\n",
        "\n",
        "    lab = cv2.cvtColor(cv2_image_copy, cv2.COLOR_BGR2LAB)\n",
        "    l_channel, a, b = cv2.split(lab)\n",
        "\n",
        "    clahe = cv2.createCLAHE(clipLimit=15.0, tileGridSize=(8, 8))\n",
        "    cl = clahe.apply(l_channel)\n",
        "\n",
        "    limg = cv2.merge((cl, a, b))\n",
        "\n",
        "    enhanced_img = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n",
        "    enhanced_img = gradient(enhanced_img)\n",
        "\n",
        "    # --------------------------\n",
        "    # Apply Canny edge detection\n",
        "    # --------------------------\n",
        "\n",
        "    edges = cv2.Canny(enhanced_img, 50, 150)\n",
        "\n",
        "    if resize:\n",
        "        standard_size = (256, 256)\n",
        "        resized_edges = cv2.resize(edges, standard_size, interpolation=cv2.INTER_AREA)\n",
        "    else:\n",
        "        resized_edges = edges\n",
        "\n",
        "    return resized_edges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_row(row):\n",
        "    latitude, longitude = row.latitude, row.longitude\n",
        "    return preprocessed_image_from_coords(latitude, longitude)\n",
        "\n",
        "def create_hdf5_dataset(df, dataset_name='features', target_shape=(256, 256), batch_size=100):\n",
        "    num_samples = len(df)\n",
        "    start_idx = 0\n",
        "\n",
        "    hdf5_filename = fr'../datasets/{dataset_name}.h5'\n",
        "\n",
        "    if os.path.exists(hdf5_filename):\n",
        "        with h5py.File(hdf5_filename, 'r+') as hdf5_file:\n",
        "            dataset = hdf5_file[dataset_name]\n",
        "\n",
        "            start_idx = np.sum(dataset[:] != 0) // target_shape[0]\n",
        "            print(f\"Resuming from index {start_idx}\")\n",
        "    else:\n",
        "        with h5py.File(hdf5_filename, 'w') as hdf5_file:\n",
        "            hdf5_file.create_dataset(\n",
        "                dataset_name,\n",
        "                shape=(num_samples, *target_shape),\n",
        "                dtype=np.uint8,\n",
        "                compression='gzip',\n",
        "                compression_opts=9\n",
        "            )\n",
        "\n",
        "    with h5py.File(hdf5_filename, 'r+') as hdf5_file:\n",
        "        dataset = hdf5_file[dataset_name]\n",
        "        with ThreadPoolExecutor() as executor:\n",
        "            for batch_start in tqdm(range(start_idx, num_samples, batch_size), desc=\"Processing Batches\"):\n",
        "                batch_end = min(batch_start + batch_size, num_samples)\n",
        "                batch_rows = df.iloc[batch_start:batch_end]\n",
        "\n",
        "                batch_results = list(executor.map(process_row, batch_rows.itertuples(index=False)))\n",
        "\n",
        "                dataset[batch_start:batch_end] = np.array(batch_results, dtype=np.uint8)\n",
        "\n",
        "    print(f\"Features dataset saved as {hdf5_filename}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resuming from index 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [34:29<00:00, 147.79s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Features dataset saved as ../datasets/features2_tokyo.h5\n"
          ]
        }
      ],
      "source": [
        "create_hdf5_dataset(\n",
        "    all_features,\n",
        "    dataset_name='features2_tokyo',\n",
        "    target_shape=(256, 256),\n",
        "    batch_size=100\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "traffic-accident-analysis-K9TuC2qz",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
